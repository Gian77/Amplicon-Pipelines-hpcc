#!/bin/bash -login
 
#SBATCH --time=04:00:00					### limit of wall clock time - how long the job will run (same as -t)
#SBATCH --ntasks=1					### number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --cpus-per-task=20				### number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=32G					### memory required per node - amount of memory (in bytes)
#SBATCH --job-name demux				### you can give your job a name for easier identification (same as -J)

cd ${SLURM_SUBMIT_DIR}

conda activate qiime1

validate_mapping_file.py -m map_ITS.txt -o mapping_output

split_libraries_fastq.py -i ../raw_reads/*_R1_001.fastq -m map_ITS.txt -b ../raw_reads/*_I1_001.fastq --store_demultiplexed_fastq --barcode_type 10 -o demultiplexed_R1/ --rev_comp_mapping_barcodes -q 19 --max_barcode_errors 0
split_libraries_fastq.py -i ../raw_reads/*_R2_001.fastq -m map_ITS.txt -b ../raw_reads/*_I1_001.fastq --store_demultiplexed_fastq --barcode_type 10 -o demultiplexed_R2/ --rev_comp_mapping_barcodes -q 19 --max_barcode_errors 0

sed '/^>/s/_/\./g' "demultiplexed_R1/seqs.fna" > "demultiplexed_R1/seqs_new.fasta"
sed '/^>/s/_/\./g' "demultiplexed_R2/seqs.fna" > "demultiplexed_R2/seqs_new.fasta"
sed '/^@/s/_/\./g' "demultiplexed_R1/seqs.fastq" > "demultiplexed_R1/seqs_new.fastq"
sed '/^@/s/_/\./g' "demultiplexed_R2/seqs.fastq" > "demultiplexed_R2/seqs_new.fastq"

#split_sequence_file_on_sample_ids.py -i demultiplexed_R1/seqs.fastq --file_type fastq -o splitted/
#for f in splitted/*fastq ; do NEW=${f%.fastq}_R1.fastq; mv ${f} "${NEW}"; done
#split_sequence_file_on_sample_ids.py -i demultiplexed_R2/seqs.fastq --file_type fastq -o splitted_R2/
#for f in splitted_R2/*fastq ; do NEW=${f%.fastq}_R2.fastq; mv ${f} "${NEW}"; done
#mv splitted_R2/*R2.fastq splitted/
#rm splitted_R2/ -rf

conda deactivate
